{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":6750,"status":"ok","timestamp":1685622332901,"user":{"displayName":"Hà Hải","userId":"02289900666155783825"},"user_tz":-420},"id":"FUs6Oj1Xvgyz"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-06-05 20:48:58.440352: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-06-05 20:48:58.568988: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2023-06-05 20:48:58.571962: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n","2023-06-05 20:48:58.571979: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","2023-06-05 20:48:59.169949: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n","2023-06-05 20:48:59.170040: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n","2023-06-05 20:48:59.170047: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"]}],"source":["import numpy as np\n","import random\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import RMSprop\n","from collections import deque \n","from tensorflow import gather_nd\n","from tensorflow.keras.losses import mean_squared_error \n","import pandas as pd\n","from functions_final import DeepQLearning"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":102137,"status":"ok","timestamp":1685622326155,"user":{"displayName":"Hà Hải","userId":"02289900666155783825"},"user_tz":-420},"id":"8f-bQUBdvgyy","outputId":"072377f3-e2f8-4234-dfa6-a30dc7a986b5"},"outputs":[],"source":["# # Load the Drive helper and mount\n","# from google.colab import drive\n","\n","# # This will prompt for authorization.\n","# drive.mount('/content/drive')\n","\n","# TRAIN_PATH='/content/drive/MyDrive/UIT/HocKy8/KLTN/detect_attack_by_reinforcement_learning/data/matrix1/normal/train-normal.csv'\n","# dataset = pd.read_csv(TRAIN_PATH)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["TRAIN_PATH='../data/matrix1/normal/train-normal.csv'\n","dataset = pd.read_csv(TRAIN_PATH)\n","# print(type(dataset))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Train model"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1685622336822,"user":{"displayName":"Hà Hải","userId":"02289900666155783825"},"user_tz":-420},"id":"rzSiskhpvgy0"},"outputs":[],"source":["# select the parameters\n","gamma=1\n","# probability parameter for the epsilon-greedy approach\n","epsilon=0.1\n","# number of training episodes\n","# NOTE HERE THAT AFTER CERTAIN NUMBERS OF EPISODES, WHEN THE PARAMTERS ARE LEARNED\n","# THE EPISODE WILL BE LONG, AT THAT POINT YOU CAN STOP THE TRAINING PROCESS BY PRESSING CTRL+C\n","# DO NOT WORRY, THE PARAMETERS WILL BE MEMORIZED\n","# numberEpisodes=100\n","\n","state_size = 38  # column in dataset exculde label\n","action_size = 2\n","batch_size = 100 # mô hình cập nhật sau khi train 100 dữ liệu\n","# episodes = data.shape[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":525947,"status":"error","timestamp":1685623035969,"user":{"displayName":"Hà Hải","userId":"02289900666155783825"},"user_tz":-420},"id":"0VSzeP5bvgy0","outputId":"fea0c0e7-1e30-44d2-e32f-fa88cf2d707e"},"outputs":[],"source":["for i in range(0,len(dataset),batch_size):\n","\n","    mini_batch = dataset[i : i + batch_size]\n","    # print(mini_batch)\n","    # create an object\n","    LearningQDeep = DeepQLearning(mini_batch,state_size,action_size,gamma,epsilon,batch_size)\n","    # run the learning process\n","    LearningQDeep.trainingEpisodes()\n","    # get the obtained rewards in every episode\n","    LearningQDeep.sumRewardsEpisode\n","    #  summarize the model\n","    LearningQDeep.mainNetwork.summary()\n","    # save the model, this is important, since it takes long time to train the model \n","    # and we will need model in another file to visualize the trained model performance\n","    LearningQDeep.mainNetwork.save(\"trained_model_temp.h5\")\n","\n","    print(\"done\",i,\"in dataset \",len(dataset))\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
